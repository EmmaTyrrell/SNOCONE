{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2c700c-1ac3-412d-bb4c-5488b26bf772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n",
      "modules established\n",
      "Baseline\n",
      "MODEL OUTPUTS TO BE PRINTED TO THIS DOC\n",
      "Processing year 2022\n",
      "Processing year 2023\n",
      "Processing year 2024\n",
      "\n",
      "Shape of input data\n",
      "feature shape: (66, 256, 256, 22)\n",
      "target shape: (66, 65536)\n",
      "22\n",
      "[]\n",
      "***\n",
      "________________________________ Training and Validation Data Shapes ________________________________\n",
      "Training data shape: (56, 256, 256, 22) (56, 65536)\n",
      "Validation data shape: (10, 256, 256, 22) (10, 65536)\n",
      "***\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 64)      12736     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 254, 254, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 127, 127, 64)     0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 125, 125, 128)    512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 62, 62, 128)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 60, 60, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 30, 30, 128)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 14, 14, 128)      0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 65536)             33619968  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,851,136\n",
      "Trainable params: 46,849,216\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/2 [==============>...............] - ETA: 11s - loss: 0.0367 - masked_rmse: 0.1917 - masked_mae: 0.0852 - masked_mse: 0.0367"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential/batch_normalization/FusedBatchNormGradV3' defined at (most recent call last):\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\etyrr\\AppData\\Local\\Temp\\ipykernel_27980\\2890717995.py\", line 189, in <module>\n      history = model.fit(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/batch_normalization/FusedBatchNormGradV3'\nOOM when allocating tensor with shape[32,64,254,254] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/batch_normalization/FusedBatchNormGradV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2633]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 189\u001b[0m\n\u001b[0;32m    186\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m DataGenerator(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m    187\u001b[0m valid_generator \u001b[38;5;241m=\u001b[39m DataGenerator(X_valid, y_valid, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m--> 189\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m## plotting results \u001b[39;00m\n\u001b[0;32m    197\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential/batch_normalization/FusedBatchNormGradV3' defined at (most recent call last):\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\etyrr\\AppData\\Local\\Temp\\ipykernel_27980\\2890717995.py\", line 189, in <module>\n      history = model.fit(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 576, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 634, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"C:\\Users\\etyrr\\anaconda3\\envs\\basins-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 510, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential/batch_normalization/FusedBatchNormGradV3'\nOOM when allocating tensor with shape[32,64,254,254] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential/batch_normalization/FusedBatchNormGradV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2633]"
     ]
    }
   ],
   "source": [
    "# pseduo code\n",
    "import sys\n",
    "sys.path.append(\"D:/ASOML/SNOCONE\")\n",
    "from CNN_memoryOptimization import clear_memory, memory_efficient_prediction, DataGenerator\n",
    "from CNN_preProcessing import*\n",
    "from CNN_benchmarks import swe_fsca_consistency_loss_fn, make_swe_fsca_loss, masked_loss_fn, masked_mse, masked_mae, masked_rmse\n",
    "from CNN_modelArchitectureBlocks import conv_block, identity_block, basic_block, resnet_model_implementation, model_predict, load_and_prepare_model, Baseline_CNN\n",
    "import rasterio\n",
    "import shap\n",
    "import pandas as pd\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import from_bounds\n",
    "import psutil\n",
    "from rasterio.transform import from_bounds \n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation, Input, Add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.transform import from_bounds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.losses import Loss\n",
    "import gc\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"modules established\")\n",
    "\n",
    "## establish file paths\n",
    "# years = list(range(2022, 2023))\n",
    "start_year = 2022\n",
    "end_year = 2024\n",
    "Domain = \"Rockies\"\n",
    "GPU = \"N\"\n",
    "\n",
    "# workspaces\n",
    "WorkspaceBase = f\"D:/ASOML/{Domain}/\"\n",
    "phv_features = WorkspaceBase + \"features/scaled/\"\n",
    "tree_workspace = WorkspaceBase + \"treeCover/\"\n",
    "land_workspace = WorkspaceBase + \"landCover/\"\n",
    "modelOuptuts = WorkspaceBase + \"modelOutputs/BasinSpecifics/\"\n",
    "DMFSCAWorkspace = WorkspaceBase + \"Rockies_DMFSCA/\"\n",
    "final_activation = 'relu'\n",
    "architectures = ['Baseline']  # Options are: Baseline, ResNet18, ResNet34, ResNet50, CustomSWE\n",
    "basin_list = ['BigThompson', 'BlueRiver', 'BoulderCreek', 'ClearCreek', 'Conejos', 'Dolores', \n",
    "              'EastRiver', 'GunnisonNorth', 'Poudre', 'RioGrande','RoaringFork', 'SouthPlatte', \n",
    "              'StVrainLefthand', 'Taylor', 'UintaMountains', 'WindyGap', 'YampaRiver']\n",
    "\n",
    "test_groups = [\n",
    "            ('Group1', 2025, 'G1'),\n",
    "            ('Group2', 2025, 'G2'), \n",
    "            ('Group3', 2025, 'G3'),\n",
    "            ('Group4', 2025, 'G4'),\n",
    "            ('Group5', 2025, 'G5'),\n",
    "            ('Group6', 2025, 'G6')\n",
    "        ]\n",
    "\n",
    "_mae_metric = MeanAbsoluteError()\n",
    "_mse_metric = MeanSquaredError()\n",
    "_rmse_metric = MeanSquaredError()\n",
    "\n",
    "# Check GPU availability\n",
    "if GPU == \"Y\":\n",
    "    print(\"\\n Checking and start running on GPU\")\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "    \n",
    "    # Configure GPU memory growth (prevents TensorFlow from allocating all GPU memory)\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"GPU memory growth enabled\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    \n",
    "    # Verify TensorFlow is using GPU\n",
    "    with tf.device('/GPU:0'):\n",
    "        a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "        b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"GPU computation result:\", c)\n",
    "\n",
    "for basin_name in basin_list:\n",
    "    for architecture in architectures:\n",
    "        print(architecture)\n",
    "        # shapeChecks = \"N\"\n",
    "        ## seting folder\n",
    "        from datetime import datetime\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        # create folder for model outputs\n",
    "        os.makedirs(modelOuptuts + f\"{basin_name}_{str(timestamp)}/\", exist_ok=True)\n",
    "        inter_model_outWorkspace = modelOuptuts + f\"{str(timestamp)}/\"\n",
    "        \n",
    "        # f = open(inter_model_outWorkspace + f\"code_output_{timestamp}.txt\", \"a\")\n",
    "        # sys.stdout = f\n",
    "        print(\"MODEL OUTPUTS TO BE PRINTED TO THIS DOC\")\n",
    "        X, y, featureNames = target_feature_stacks_basins(start_year=start_year, \n",
    "                                                   end_year=end_year, \n",
    "                                                   WorkspaceBase=WorkspaceBase, \n",
    "                                                   ext = \"nonull_fnl.tif\", \n",
    "                                                   vegetation_path = tree_workspace, \n",
    "                                                   landCover_path = land_workspace, \n",
    "                                                   phv_path = phv_features , \n",
    "                                                   target_shape=(256,256),\n",
    "                                                   basin_name=basin_name,\n",
    "                                                   shapeChecks=\"Y\")\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Shape of input data\")\n",
    "        print(f\"feature shape: {X.shape}\")\n",
    "        print(f\"target shape: {y.shape}\")\n",
    "        feat_shape = X.shape\n",
    "        featNo = feat_shape[-1]\n",
    "        print(featNo)\n",
    "        print(featureNames)\n",
    "        \n",
    "        # split between training and test data\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, shuffle=True)\n",
    "        print(\"***\")\n",
    "        print(\"________________________________ Training and Validation Data Shapes ________________________________\")\n",
    "        print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "        print(\"Validation data shape:\", X_valid.shape, y_valid.shape)\n",
    "        print(\"***\")\n",
    "        x_trainShape = X_train.shape\n",
    "        x_validShape = X_valid.shape\n",
    "        \n",
    "        # Assuming featNo and final_activation are defined in your original code\n",
    "        featNo = featNo  # Replace with your actual feature count\n",
    "        final_activation = final_activation  # Replace with your actual activation\n",
    "        \n",
    "        # Create the model\n",
    "        model = resnet_model_implementation(featNo, architecture, final_activation)\n",
    "        \n",
    "        # Your existing custom loss function\n",
    "        from tensorflow.keras.losses import MeanSquaredError\n",
    "        from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "        \n",
    "        custom_loss_fn = make_swe_fsca_loss(\n",
    "            base_loss_fn=MeanSquaredError(),\n",
    "            penalty_weight=0.3,\n",
    "            swe_threshold=0.01,\n",
    "            fsca_threshold=0.01,\n",
    "            mask_value=-1\n",
    "        )\n",
    "        \n",
    "        # Compile with your existing setup\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=custom_loss_fn,\n",
    "            metrics=[masked_rmse, masked_mae, masked_mse]\n",
    "        )\n",
    "        \n",
    "        print(model.summary())\n",
    "        \n",
    "        # establish the model\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            f\"{inter_model_outWorkspace}/best_model_{basin_name}_{timestamp}.weights.h5\", \n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1, \n",
    "            save_best_only=True, mode='min'\n",
    "        )\n",
    "        early_stopping = EarlyStopping(monitor=\"val_masked_rmse\", mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "        \n",
    "        \n",
    "        batch_size = 32\n",
    "        train_generator = DataGenerator(X_train, y_train, batch_size=batch_size)\n",
    "        valid_generator = DataGenerator(X_valid, y_valid, batch_size=batch_size)\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=valid_generator,\n",
    "            epochs=100,\n",
    "            callbacks=[checkpoint, early_stopping]\n",
    "        )\n",
    "    \n",
    "        ## plotting results \n",
    "        fig, axs = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "        # 1. Masked MSE (used as loss)\n",
    "        axs[0].plot(history.history['loss'], label='Train MSE Loss')\n",
    "        axs[0].plot(history.history['val_loss'], label='Val MSE Loss')\n",
    "        axs[0].set_ylabel('MSE Loss')\n",
    "        axs[0].set_title('Masked MSE')\n",
    "        axs[0].legend()\n",
    "        axs[0].grid(True)\n",
    "        # 2. Masked RMSE\n",
    "        axs[1].plot(history.history['masked_rmse'], label='Train RMSE')\n",
    "        axs[1].plot(history.history['val_masked_rmse'], label='Val RMSE')\n",
    "        axs[1].set_ylabel('RMSE')\n",
    "        axs[1].set_title('Masked RMSE')\n",
    "        axs[1].legend()\n",
    "        axs[1].grid(True)\n",
    "        # 3. Masked MAE\n",
    "        axs[2].plot(history.history['masked_mae'], label='Train MAE')\n",
    "        axs[2].plot(history.history['val_masked_mae'], label='Val MAE')\n",
    "        axs[2].set_ylabel('MAE')\n",
    "        axs[2].set_title('Masked MAE')\n",
    "        axs[2].set_xlabel('Epoch')\n",
    "        axs[2].legend()\n",
    "        axs[2].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(inter_model_outWorkspace + f\"{basin_name}_Model_error_epochs.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        ## Add metrics to recurring error tracking sheet\n",
    "        metrics_to_track = ['val_masked_rmse', 'val_masked_mse', 'val_masked_mae']\n",
    "        best_metrics = {}\n",
    "        print(\"\\nValidation Metric Progression:\")\n",
    "        for metric in metrics_to_track:\n",
    "            values = history.history.get(metric, [])\n",
    "            if values:\n",
    "                best_val = min(values)\n",
    "                best_metrics[metric] = best_val\n",
    "                print(f\"{metric}: Start = {values[0]:.4f}, End = {values[-1]:.4f}\")\n",
    "                print(f\"{metric}: Best = {best_val:.4f}\")\n",
    "            else:\n",
    "                print(f\"{metric}: Not found in history.\")\n",
    "        print(f\"Final activation function: {final_activation}\")\n",
    "        \n",
    "        # Example variables\n",
    "        feature_csv = modelOuptuts + f\"{Domain}_{basin_name}_model_featureList_summary.csv\" \n",
    "        column_name = timestamp  \n",
    "        feature_list = featureNames    \n",
    "        new_column_df = pd.DataFrame({column_name: feature_list})\n",
    "        \n",
    "        # If the file already exists, load it and append the new column\n",
    "        if os.path.exists(feature_csv):\n",
    "            existing_df = pd.read_csv(feature_csv)\n",
    "            # Reindex the existing dataframe \n",
    "            max_len = max(len(existing_df), len(new_column_df))\n",
    "            existing_df = existing_df.reindex(range(max_len))\n",
    "            new_column_df = new_column_df.reindex(range(max_len))\n",
    "            # Combine horizontally\n",
    "            combined_df = pd.concat([existing_df, new_column_df], axis=1)\n",
    "        else:\n",
    "            combined_df = new_column_df\n",
    "        \n",
    "        # Save back to CSV\n",
    "        combined_df.to_csv(feature_csv, index=False)\n",
    "        \n",
    "        # add metrics to csv\n",
    "        modelStatsCSV = modelOuptuts + f\"{Domain}_{basin_name}_modelSummary_stats.csv\"\n",
    "        \n",
    "        error_stats = {\n",
    "            'ModelRun':[timestamp],\n",
    "            'FeatureNum': [featNo],\n",
    "            'Architecture': [architecture],\n",
    "            'FinalActivation': [final_activation],\n",
    "            'X_TrainShape': [x_trainShape[0]],\n",
    "            'X_ValidShape': [x_validShape[0]],\n",
    "            'RMSE': [best_metrics['val_masked_rmse']],\n",
    "            'MSE': [best_metrics['val_masked_mse']], \n",
    "            'MAE': [best_metrics['val_masked_mae']]\n",
    "            \n",
    "        }\n",
    "        \n",
    "        df = pd.DataFrame(error_stats)\n",
    "        \n",
    "        # Append or write new file\n",
    "        if os.path.exists(modelStatsCSV):\n",
    "            df.to_csv(modelStatsCSV, mode='a', header=False, index=False)\n",
    "        else:\n",
    "            df.to_csv(modelStatsCSV, index=False)\n",
    "        \n",
    "        del X_train, X_valid, y_train, y_valid, X, y\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "    \n",
    "        del history \n",
    "        clear_memory()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94c1699-6351-4395-add2-607fcc6e89d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
