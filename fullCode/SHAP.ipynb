{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655dba90-a1d5-4ada-a8c5-c5e2207f1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules imported\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import sys\n",
    "sys.path.append(\"D:/ASOML/SNOCONE\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from CNN_benchmarks import*\n",
    "from CNN_memoryOptimization import*\n",
    "from CNN_preProcessing import*\n",
    "from CNN_benchmarks import*\n",
    "from CNN_modelArchitectureBlocks import*\n",
    "\n",
    "def run_shap(weights_path, X_sample, feature_names, featNo, architecture, final_activation, custom_loss_fn, output_dir=None):\n",
    "    \"\"\"\n",
    "    SHAP feature importance analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights_path : str - Path to .h5 weights file\n",
    "    X_sample : numpy.ndarray - Sample data (shape: samples, height, width, features)\n",
    "    feature_names : list - List of feature names\n",
    "    featNo : int - Number of features\n",
    "    architecture : str - Model architecture name\n",
    "    final_activation : str - Final activation function\n",
    "    custom_loss_fn : function - Custom loss function\n",
    "    output_dir : str, optional - Directory to save results (CSV + plots)\n",
    "    \n",
    "    Returns: DataFrame with feature importance rankings\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load model\n",
    "    print(\"Loading model...\")\n",
    "    model = resnet_model_implementation(featNo, architecture, final_activation)\n",
    "    model.load_weights(weights_path)\n",
    "    model.compile(optimizer='adam', loss=custom_loss_fn, metrics=[masked_rmse, masked_mae, masked_mse])\n",
    "    \n",
    "    # SHAP analysis\n",
    "    print(\"Creating SHAP explainer...\")\n",
    "    background = X_sample[:20]\n",
    "    explainer = shap.GradientExplainer(model, background)\n",
    "    \n",
    "    print(\"Calculating SHAP values...\")\n",
    "    X_explain = X_sample[:10]\n",
    "    shap_values = explainer.shap_values(X_explain)\n",
    "    \n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[0]\n",
    "    \n",
    "    print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "    \n",
    "    # Calculate feature importance\n",
    "    if len(shap_values.shape) == 4:  # (samples, height, width, features)\n",
    "        feature_importance = np.mean(np.abs(shap_values), axis=(0, 1, 2))\n",
    "    else:\n",
    "        feature_importance = np.mean(np.abs(shap_values), axis=0)\n",
    "    \n",
    "    # Create results\n",
    "    results = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'SHAP_Importance': feature_importance,\n",
    "        'Normalized_Importance': feature_importance / np.max(feature_importance)\n",
    "    }).sort_values('SHAP_Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    results['Rank'] = range(1, len(results) + 1)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nFeature Importance Rankings:\")\n",
    "    print(results[['Rank', 'Feature', 'SHAP_Importance']].to_string(index=False))\n",
    "    \n",
    "    # Save files if output directory provided\n",
    "    if output_dir is not None:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save CSV\n",
    "        csv_path = os.path.join(output_dir, 'feature_importance.csv')\n",
    "        results.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nCSV saved: {csv_path}\")\n",
    "        \n",
    "        # Create plots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Bar chart\n",
    "        colors = plt.cm.viridis(results['Normalized_Importance'])\n",
    "        ax1.barh(range(len(results)), results['SHAP_Importance'], color=colors)\n",
    "        ax1.set_yticks(range(len(results)))\n",
    "        ax1.set_yticklabels(results['Feature'])\n",
    "        ax1.set_xlabel('SHAP Importance')\n",
    "        ax1.set_title('SWE Feature Importance')\n",
    "        ax1.invert_yaxis()\n",
    "        \n",
    "        # Line plot\n",
    "        ax2.plot(range(1, len(results)+1), results['SHAP_Importance'], 'o-', \n",
    "                linewidth=2, markersize=8, color='steelblue')\n",
    "        ax2.set_xlabel('Rank')\n",
    "        ax2.set_ylabel('SHAP Importance')\n",
    "        ax2.set_title('Feature Importance by Rank')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Annotate top 5\n",
    "        for i in range(min(5, len(results))):\n",
    "            ax2.annotate(results.iloc[i]['Feature'], \n",
    "                        (i+1, results.iloc[i]['SHAP_Importance']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = os.path.join(output_dir, 'feature_importance_plot.png')\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved: {plot_path}\")\n",
    "        plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4c1d874-6c2b-4315-b57f-e559acc9656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Domain = \"Rockies\"\n",
    "WorkspaceBase = f\"D:/ASOML/{Domain}/\"\n",
    "ModelOutputs = f\"{WorkspaceBase}/modelOutputs/\"\n",
    "model_interation = \"20250713_152730\"\n",
    "feature_Listcsv = f\"{ModelOutputs}/{Domain}_model_featureList_summary.csv\"\n",
    "best_weights = ModelOutputs + f\"/{model_interation}/best_weights_{model_interation}.h5\"\n",
    "start_year = 2022\n",
    "end_year = 2022\n",
    "shap_output = f\"{ModelOutputs}/{model_interation}/shap_results/\"\n",
    "architecture = \"Baseline\"\n",
    "shapeChecks = \"N\"\n",
    "\n",
    "# workspaces\n",
    "phv_features = WorkspaceBase + \"features/scaled/\"\n",
    "tree_workspace = WorkspaceBase + \"treeCover/\"\n",
    "land_workspace = WorkspaceBase + \"landCover/\"\n",
    "modelOuptuts = WorkspaceBase + \"modelOutputs/\"\n",
    "DMFSCAWorkspace = WorkspaceBase + \"Rockies_DMFSCA/\"\n",
    "\n",
    "## get list of features\n",
    "feat_df = pd.read_csv(feature_Listcsv)\n",
    "feat_names = feat_df[[f'{model_interation}']]\n",
    "featNo = len(feat_df)\n",
    "feature_names = feat_names[f'{model_interation}'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722dc19e-92f0-4ca2-b428-11f6c13d09d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2022\n"
     ]
    }
   ],
   "source": [
    "X_sample, y_sample, featureNames = target_feature_stacks_SHAP(start_year=start_year, \n",
    "                                           end_year=end_year, \n",
    "                                           WorkspaceBase=WorkspaceBase, \n",
    "                                           ext = \"nonull_fnl.tif\", \n",
    "                                           vegetation_path = tree_workspace, \n",
    "                                           landCover_path = land_workspace, \n",
    "                                           phv_path = phv_features , \n",
    "                                           target_shape=(256,256), shapeChecks=shapeChecks, desired_features=feature_names,\n",
    "                                           expected_channels=featNo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d1b3b-1666-4b55-a9c7-3a07c560b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your loss function first\n",
    "custom_loss_fn = make_swe_fsca_loss(\n",
    "    base_loss_fn=MeanSquaredError(),\n",
    "    penalty_weight=0.3,\n",
    "    swe_threshold=0.01,\n",
    "    fsca_threshold=0.01,\n",
    "    mask_value=-1\n",
    ")\n",
    "\n",
    "# Then use it\n",
    "results = run_shap(weights_path=best_weights, X_sample=X_sample, feature_names=featureNames, featNo=featNo, architecture=architecture, \n",
    "                   final_activation=\"relu\", custom_loss_fn=custom_loss_fn, output_dir=shap_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f923e-afd3-4114-8842-eddc89054864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
